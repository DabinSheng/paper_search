#!/usr/bin/env python3
"""æµ‹è¯•Google Scholarè§£ææ”¹è¿›"""

from search_engines import GoogleScholarSearchEngine

def test_scholar_search():
    """æµ‹è¯•Google Scholaræœç´¢å’Œè§£æ"""
    engine = GoogleScholarSearchEngine()
    
    # æµ‹è¯•å…³é”®è¯
    keywords = "deep learning"
    print(f"ğŸ” æµ‹è¯•æœç´¢: {keywords}\n")
    
    # æ‰§è¡Œæœç´¢ï¼ˆåªè·å–5ç¯‡ä½œä¸ºæµ‹è¯•ï¼‰
    from config import Config
    original_max = Config.MAX_RESULTS
    Config.MAX_RESULTS = 5  # ä¸´æ—¶è®¾ç½®ä¸º5
    
    try:
        papers = engine.search(keywords)
        
        print(f"\nğŸ“Š æœç´¢ç»“æœç»Ÿè®¡:")
        print(f"æ€»å…±æ‰¾åˆ°: {len(papers)} ç¯‡è®ºæ–‡\n")
        
        for idx, paper in enumerate(papers, 1):
            print(f"{'='*60}")
            print(f"è®ºæ–‡ {idx}:")
            print(f"æ ‡é¢˜: {paper.title}")
            print(f"æ‘˜è¦é•¿åº¦: {len(paper.abstract)} å­—ç¬¦")
            print(f"æ‘˜è¦é¢„è§ˆ: {paper.abstract[:150]}...")
            print(f"URL: {paper.url}")
            print(f"PDF: {paper.pdf_url if paper.pdf_url else 'âŒ æ— PDFé“¾æ¥'}")
            print(f"ä½œè€…: {', '.join(paper.authors) if paper.authors else 'æœªæå–åˆ°ä½œè€…'}")
            print()
        
        # ç»Ÿè®¡
        with_pdf = sum(1 for p in papers if p.pdf_url)
        with_abstract = sum(1 for p in papers if len(p.abstract) > 100)
        
        print(f"\nğŸ“ˆ è´¨é‡ç»Ÿè®¡:")
        print(f"  æœ‰PDFé“¾æ¥: {with_pdf}/{len(papers)} ({with_pdf/len(papers)*100:.1f}%)")
        print(f"  å®Œæ•´æ‘˜è¦: {with_abstract}/{len(papers)} ({with_abstract/len(papers)*100:.1f}%)")
        
    finally:
        Config.MAX_RESULTS = original_max

if __name__ == "__main__":
    test_scholar_search()
